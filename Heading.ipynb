{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import sys\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_image(PDF_file):\n",
    "    \n",
    "    # Store all the pages of the PDF in a variable\n",
    "    pages = convert_from_path(PDF_file, 500)\n",
    "    # Counter to store images of each page of PDF to image\n",
    "    image_counter = 0\n",
    "    # Iterate through all the pages stored above\n",
    "    for page in pages:\n",
    "        # Declaring filename for each page of PDF as JPG\n",
    "        # For each page, filename will be:\n",
    "        # PDF page 1 -> page_1.jpg\n",
    "        # PDF page 2 -> page_2.jpg\n",
    "        # PDF page 3 -> page_3.jpg\n",
    "        # ....\n",
    "        # PDF page n -> page_n.jpg\n",
    "        filename = \"image_\"+str(image_counter)+\".jpg\"\n",
    "        # Save the image of the page in system\n",
    "        page.save(filename, 'JPEG')\n",
    "        # Increment the counter to update filename\n",
    "        image_counter = image_counter + 1\n",
    "    return image_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_ocr(dir_path, filelimit):\n",
    "    # Creating a text file to write the output\n",
    "    ocr_file = \"\".join((dir_path,\"/ocr.txt\"))\n",
    "    # Open the file in append mode so that \n",
    "    # All contents of all images are added to the same file\n",
    "    f = open(ocr_file, \"w\")\n",
    "    # Iterate from 1 to total number of pages\n",
    "    for i in range(0, filelimit):\n",
    "\n",
    "        # Set filename to recognize text from\n",
    "        # Again, these files will be:\n",
    "        # page_1.jpg\n",
    "        # page_2.jpg\n",
    "        # ....\n",
    "        # page_n.jpg\n",
    "        filename = \"image_\"+str(i)+\".jpg\"\n",
    "\n",
    "        # Recognize the text as string in image using pytesserct\n",
    "        text = str(((pytesseract.image_to_string(Image.open(filename)))))\n",
    "\n",
    "        # The recognized text is stored in variable text\n",
    "        # Any string processing may be applied on text\n",
    "        # Here, basic formatting has been done:\n",
    "        # In many PDFs, at line ending, if a word can't\n",
    "        # be written fully, a 'hyphen' is added.\n",
    "        # The rest of the word is written in the next line\n",
    "        # Eg: This is a sample text this word here GeeksF-\n",
    "        # orGeeks is half on first line, remaining on next.\n",
    "        # To remove this, we replace every '-\\n' to ''.\n",
    "        text = text.replace('-\\n', '')    \n",
    "\n",
    "        # Finally, write the processed text to the file.\n",
    "        f.write(text)\n",
    "\n",
    "    # Close the file after writing all the text.\n",
    "    f.close()    \n",
    "    \n",
    "    return ocr_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_headings(text):\n",
    "    length = len(text)\n",
    "    heading = ['title', 'abstract']\n",
    "    sub_heading = heading.copy()\n",
    "    number = 1\n",
    "    for i in range(1, length):\n",
    "        \n",
    "        if(text[i] == 'References'):\n",
    "            break\n",
    "        tokens = text[i].split()\n",
    "        if(len(tokens) <= 1 or len(tokens[0]) > 4 or len(tokens) >= 10 or tokens[1][0].islower() \n",
    "           or not tokens[1][0].isalpha()):\n",
    "            continue\n",
    "        if(ord(tokens[0][0]) >= number+47 and ord(tokens[0][0]) <= number+49):\n",
    "            if(len(tokens[0]) == 1 and len(tokens)<=6 and \n",
    "               (tokens[0] == str(number) or tokens[0] == str(number+1))):\n",
    "                head = \" \".join(tokens[1:])\n",
    "                heading.append(head)\n",
    "                sub_heading.append(head)\n",
    "                number += 1\n",
    "                if (tokens[0] == str(number+1)):\n",
    "                    number += 1\n",
    "            if(len(tokens[0]) == 2 and len(tokens)<=6 and tokens[0][1] == '.' and \n",
    "               (tokens[0][0] == str(number) or tokens[0][0] == str(number+1))):\n",
    "                head = \" \".join(tokens[1:])\n",
    "                heading.append(head)\n",
    "                sub_heading.append(head)\n",
    "                number += 1\n",
    "                if(tokens[0] == str(number+1)+'.'):\n",
    "                    number += 1\n",
    "            if(len(tokens[0]) == 3 and (tokens[0][0] == str(number) or tokens[0][0] == str(number-1)) \n",
    "               and tokens[0][1] == '.'):\n",
    "                head = \" \".join(tokens[1:])\n",
    "                sub_heading.append(head)\n",
    "                if(tokens[0][0:2] == str(number)+'.'):\n",
    "                    number += 1\n",
    "            if(len(tokens[0]) == 4 and (tokens[0][0] == str(number) or tokens[0][0] == str(number-1)) \n",
    "               and tokens[0][1] == '.' and tokens[0][3] == '.'):\n",
    "                head = \" \".join(tokens[1:])\n",
    "                sub_heading.append(head)\n",
    "                if(tokens[0][0:2] == str(number)+'.'):\n",
    "                    number += 1\n",
    "    return heading, sub_heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_heading_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../NCG_Dataset/training-data-master/text_summarization/0\n",
      "../NCG_Dataset/training-data-master/sentiment_analysis/51\n",
      "../NCG_Dataset/training-data-master/sentiment_analysis/8\n",
      "../NCG_Dataset/training-data-master/sentiment_analysis/19\n",
      "../NCG_Dataset/training-data-master/sentiment_analysis/35\n",
      "../NCG_Dataset/training-data-master/natural_language_inference/99\n",
      "../NCG_Dataset/training-data-master/natural_language_inference/45\n",
      "../NCG_Dataset/training-data-master/natural_language_inference/7\n",
      "../NCG_Dataset/training-data-master/natural_language_inference/2\n",
      "../NCG_Dataset/training-data-master/natural_language_inference/38\n",
      "../NCG_Dataset/training-data-master/natural_language_inference/89\n",
      "../NCG_Dataset/training-data-master/natural_language_inference/15\n",
      "../NCG_Dataset/training-data-master/natural_language_inference/67\n",
      "../NCG_Dataset/training-data-master/text_generation/2\n"
     ]
    }
   ],
   "source": [
    "path = \"../NCG_Dataset/training-data-master/*/*\"\n",
    "directory = glob.glob(path)\n",
    "#print(len(directory))\n",
    "for dir_path in directory:\n",
    "    start_time = time.time()\n",
    "    file = \"\".join((dir_path,\"/main_heading.txt\"))\n",
    "    if(os.path.isfile(file)):\n",
    "        continue\n",
    "    print(dir_path)\n",
    "    file = \"\".join((dir_path,\"/*.pdf\"))\n",
    "    pdf_file = glob.glob(file)[0]\n",
    "    #print(pdf_file)\n",
    "    pages = pdf_image(pdf_file)\n",
    "    #print(pages)\n",
    "    ocr_file = image_ocr(dir_path, pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../NCG_Dataset/training-data-master/*/*\"\n",
    "directory = glob.glob(path)\n",
    "#print(len(directory))\n",
    "for dir_path in directory:\n",
    "    file = \"\".join((dir_path,\"/ocr.txt\"))\n",
    "    if(os.path.isfile(file) == False):\n",
    "        print(dir_path)\n",
    "        continue\n",
    "    f = open(file, 'r')\n",
    "    text = f.readlines()\n",
    "    text = [line.strip() for line in text]\n",
    "    #print(len(text))\n",
    "    heading, sub_heading = extract_headings(text)\n",
    "    file = \"\".join((dir_path,\"/main_heading.txt\"))\n",
    "    f = open(file, 'w')\n",
    "    for head in heading:\n",
    "        f.write(head+\"\\n\")\n",
    "    f.close()\n",
    "    file = \"\".join((dir_path,\"/sub_heading.txt\"))\n",
    "    f = open(file, 'w')\n",
    "    for head in sub_heading:\n",
    "        f.write(head+\"\\n\")\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
