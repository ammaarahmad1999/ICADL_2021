{
  "has" : {
    "Model" : {
      "introduce" : {
        "extension to the encoder - decoder model" : {
          "learns to" : "align and translate jointly"
        },
        "from sentence" : "In order to address this issue , we introduce an extension to the encoder - decoder model which learns to align and translate jointly ."
      },
      "( soft - ) searches" : {
        "set of positions" : {
          "in" : {
            "source sentence" : {
              "where" : "most relevant information is concentrated"
            }
          }
        },
        "Each time" : {
          "generates" : {
            "word" : {
              "in" : "translation"       
            }
          }
        },
        "from sentence" : "Each time the proposed model generates a word in a translation , it ( soft - ) searches for a set of positions in a source sentence where the most relevant information is concentrated ."        
      },
      "predicts" : {
        "target word" : {
          "based on" : [
            {"context vectors" : {
              "associated with" : "source positions"
            }},
            "previous generated target words"
          ]
        },
        "from sentence" : "The model then predicts a target word based on the context vectors associated with these source positions and all the previous generated target words ."
      }
    }
  }
}