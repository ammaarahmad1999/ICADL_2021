(Contribution||has||Model)
(Model||has||Encoder and Decoder Stacks)
(Encoder and Decoder Stacks||has||Encoder)
(Encoder||employ||residual connection)
(residual connection||around||two sub-layers)
(two sub-layers||followed by||layer normalization)
(Encoder||composed of||stack of N = 6 identical layers)
(stack of N = 6 identical layers||has||two sub-layers)
(two sub-layers||first||multi-head self - attention mechanism)
(two sub-layers||second||simple , positionwise fully connected feed - forward network)
(Encoder and Decoder Stacks||has||Decoder)
(Decoder||employ||residual connections)
(residual connections||around||each of the sub-layers)
(each of the sub-layers||followed by||layer normalization)
(Decoder||modify||self - attention sub - layer)
(self - attention sub - layer||in||decoder stack)
(decoder stack||prevent||positions from attending to subsequent positions)
(Decoder||composed of||stack of N = 6 identical layers)
(Decoder||inserts||third sub - layer)
(third sub - layer||performs||multi-head attention)
(multi-head attention||over||output of the encoder stack)
(Model||has||Attention)
(Attention||described as||mapping a query and a set of key - value pairs)
(mapping a query and a set of key - value pairs||to||output)
(output||computed as||weighted sum of the values)
(weighted sum of the values||where||weight assigned to each value)
(weight assigned to each value||computed by||compatibility function of the query)
(compatibility function of the query||with||corresponding key)
(Model||has||Scaled Dot - Product Attention)
(Model||has||Multi - Head Attention)
(Model||has||Position - wise Feed - Forward Networks)
(Position - wise Feed - Forward Networks||contains||fully connected feed - forward network)
(fully connected feed - forward network||applied to||each position separately and identically)
(each position separately and identically||consists||two linear transformations)
(two linear transformations||with||ReLU activation)
(Model||has||Embeddings and Softmax)
(Embeddings and Softmax||use||usual learned linear transformation and softmax function)
(usual learned linear transformation and softmax function||to convert||decoder output)
(decoder output||to||predicted next - token probabilities)
(Embeddings and Softmax||use||learned embeddings)
(learned embeddings||to convert||input tokens and output tokens)
(input tokens and output tokens||to||vectors of dimension d model)
(Model||has||Positional Encoding)
(Positional Encoding||add||positional encodings)
(positional encodings||to||input embeddings)
(input embeddings||at the bottoms of||encoder and decoder stacks)
(Positional Encoding||inject||some information)
(some information||about||relative or absolute position)
(relative or absolute position||of||tokens in the sequence)
