(Contribution||has||Baselines)
(Baselines||has||URAE+ MLP)
(URAE+ MLP||use||Unfolding Recursive Autoencoder)
(Unfolding Recursive Autoencoder||get||100 dimensional vector representation)
(100 dimensional vector representation||of||each sentence)
(Unfolding Recursive Autoencoder||put||an MLP)
(an MLP||on the top as in||WORDEMBED)
(Baselines||has||SENNA + MLP / SIM)
(SENNA + MLP / SIM||use||SENNA - type sentence model)
(SENNA - type sentence model||for||sentence representation)
(Baselines||has||DEEPMATCH)
(DEEPMATCH||take||matching model)
(matching model||train it on||our datasets)
(our datasets||with||3 hidden layers and 1,000 hidden nodes in the first hidden layer)
(Baselines||has||SENMLP)
(SENMLP||take||whole sentence)
(whole sentence||as||input)
(input||with||word embedding aligned sequentially)
(SENMLP||use||MLP)
(MLP||to obtain||score of coherence)
(Baselines||has||WORDEMBED)
(WORDEMBED||calculated||matching score)
(matching score||of||two short - texts)
(two short - texts||with||MLP)
(MLP||with||embedding of the two documents as input)
(WORDEMBED||represent||each short - text)
(each short - text||as||sum of the embedding of the words it contains)
