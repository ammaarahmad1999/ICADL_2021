{
  "has" : {
    "Experimental setup" : {
      "To train" : {
        "our model" : {
          "used" : {
            "stochastic gradient descent" : {
              "with" : ["ADAM optimizer", {"initial learning rate" : {
                "of" : "0.001"
              }}]
            }
          }
        },
        "from sentence" : "To train our model , we used stochastic gradient descent with the ADAM optimizer ( Kingma and Ba , 2014 ) , with an initial learning rate of 0.001 ."        
      },
      "set" : {
        "batch size" : {
          "to" : "32"
        }
      },
      "decay" : {
        "learning rate" : {
          "by" : "0.8"
        },
        "from sentence" : "We set the batch size to 32 and we decay the learning rate by 0.8 if the accuracy on the validation set does not increase after a half - epoch , i.e. 2000 batches ( for CBT ) and 5000 batches for ( CNN ) ."
      },
      "initialize" : {
        "weights of our model" : {
          "by sampling from" : "normal distribution N ( 0 , 0.05 )"
        },
        "from sentence" : "We initialize all weights of our model by sampling from the normal distribution N ( 0 , 0.05 ) ."
      },
      "are initialized" : {
        "GRU recurrent weights" : {
          "to be" : "orthogonal"
        },
        "biases" : {
          "to" : "zero"
        },
        "from sentence" : "Following , the GRU recurrent weights are initialized to be orthogonal and biases are initialized to zero ."
      },
      "to stabilize" : {
        "learning" : {
          "clip" : {
            "gradients" : {
              "if" : {
                "norm" : {
                  "greater than" : "5"
                }
              }
            }
          }
        },
        "from sentence" : "In order to stabilize the learning , we clip the gradients if their norm is greater than 5 and those marked with 2 are from ."
      },
      "implemented in" : {
        "Theano" : {
          "using" : "Keras library"
        },
        "from sentence" : "Our model is implemented in Theano , using the Keras library ."
      }
    }
  }
}