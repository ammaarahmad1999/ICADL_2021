{
  "has" : {
    "Approach" : {
      "converting questions" : {
        "to ( uninterpretable ) vectorial representations" : {
          "which require" : "no pre-defined grammars or lexicons",
          "can query" : {
            "any KB" : {
              "independent of" : "schema"
            }
          }
        },
        "from sentence" : "In this paper , we instead take the approach of converting questions to ( uninterpretable ) vectorial representations which require no pre-defined grammars or lexicons and can query any KB independent of its schema ."
      },
      "learning" : {
        "low - dimensional vector embeddings" : {
          "of" : {
            "words and of KB triples" : {
              "so that" : {
                "representations of questions and corresponding answers" : {
                  "end up" : {
                    "similar" : {
                      "in" : "embedding space"
                    }
                  }
                }
              }
            }
          }
        },
        "from sentence" : "Our approach is based on learning low - dimensional vector embeddings of words and of KB triples so that representations of questions and corresponding answers end up being similar in the embedding space ."
      },
      "make use of" : ["weak supervision", {"from sentence" : "In order to avoid transferring the cost of manual intervention to the one of labeling large amounts of data , we make use of weak supervision ."}],
      "end up learning" : {
        "meaningful vectorial representations" : {
          "for" : {
            "questions" : {
              "involving" : "up to 800 k words"
            },
            "triples" : {
              "of" : {
                "mostly automatically created KB" : {
                  "with" : ["2.4 M entities" , "600 k relationships"]
                }
              }
            }
          }
        },
        "from sentence" : "We end up learning meaningful vectorial representations for questions involving up to 800 k words and for triples of an mostly automatically created KB with 2.4 M entities and 600 k relationships ."
      },
      "propose" : {
        "fine - tune embedding - based models" : {
          "optimizing" : {
            "a matrix" : {
              "parameterizing" : {
                "similarity" : {
                  "used in" : {
                    "embedding space" : {
                      "leading to" : "consistent improvement in performance"  
                    }
                  }
                }
              }
            }
          }
        },
        "from sentence" : "Thus , we propose a method to fine - tune embedding - based models by carefully optimizing a matrix parameterizing the similarity used in the embedding space , leading to a consistent improvement in performance ."
      }
    }
  }
}