(Contribution||has||Model)
(Model||introduce||novel recurrent neural model)
(novel recurrent neural model||incorporate||entity - aware attention mechanism)
(entity - aware attention mechanism||with||LET method)
(Model||consists of||four main components)
(four main components||has||BLSTM)
(BLSTM||sequentially encodes||representations of self attention layer)
(four main components||has||Self Attention)
(Self Attention||captures||meaning of the correlation between words)
(meaning of the correlation between words||based on||multi-head attention)
(four main components||has||Entity - aware Attention)
(Entity - aware Attention||calculates||attention weights)
(attention weights||with respect to||entity pairs , word positions relative to these pairs , and their latent types obtained by LET)
(four main components||has||Word Representation)
(Word Representation||maps||each word in a sentence)
(each word in a sentence||into||vector representations)
