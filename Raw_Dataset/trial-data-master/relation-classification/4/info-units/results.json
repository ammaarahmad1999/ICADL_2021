{
  "has" : {
    "Results" : {
      "on" : {
        "TACRED Dataset" : {
          "observe" : {
            "our GCN model" : {
              "outperforms" : {
                "all dependency - based models" : {
                  "by" : "at least 1.6 F 1"
                }
              }
            },
            "from sentence" : "Results on the TACRED Dataset 
            We observe that our GCN model Our Model ( C - GCN ) 84.8 * 76.5 * outperforms all dependency - based models by at least 1.6 F 1 ."

          },
          "using" : {
            "contextualized word representations" : {
              "has" : {
                "C - GCN model" : {
                  "further outperforms"  : {
                    "strong PA - LSTM model" : {
                      "by" : "1.3 F 1"
                    }
                  }
                }
              },
              "from sentence" : "By using contextualized word representations , the C - GCN model further outperforms the strong PA - LSTM model by 1.3 F 1 , and achieves a new state of the art ."
            }
          },
          "improves" : {
            "upon other dependencybased models" : {
              "in both" : "precision and recall"
            },
            "from sentence" : "In addition , we find our model improves upon other dependencybased models in both precision and recall ."            
          },
          "Comparing" : {
            "C - GCN model" : {
              "with" : {
                "GCN model" : {
                  "find that" : {
                    "gain" : {
                      "mainly comes from" : "improved recall"
                    }
                  }
                }
              }
            },
            "from sentence" : "Comparing the C - GCN model with the GCN model , we find that the gain mainly comes from improved recall ."
          },
          "find that" : {
            "our GCN models" : {
              "have" : {
                "complementary strengths" : {
                  "when compared to" : "PA - LSTM"
                }
              }
            },
            "from sentence" : "As we will show in Section 6.2 , we find that our GCN models have complementary strengths when compared to the PA - LSTM ."
          }
        },
        "SemEval Dataset" : {
          "under" : {
            "conventional with- entity evaluation" : {
              "has" : {
                "C - GCN model" : {
                  "outperforms" : "all existing dependency - based neural models"
                }
              }
            },
            "from sentence" : "Results on the SemEval Dataset
We find that under the conventional with- entity evaluation , our C - GCN model outperforms all existing dependency - based neural models on this sep - arate dataset ."

          },
          "our model outperforms" : {
            "previous shortest dependency path - based model ( SDP - LSTM )" : {
              "by properly incorporating" : "off - path information"
            },
            "from sentence" : "Notably , by properly incorporating off - path information , our model outperforms the previous shortest dependency path - based model ( SDP - LSTM ) ."
          },
          "Under" : {
            "mask - entity evaluation" : {
              "has" : {
                "C - GCN model" : {
                  "also outperforms" : {
                    "PA - LSTM" : {
                      "by" : "substantial margin"
                    }
                  }
                }
              }
            },
            "from sentence" : "Under the mask - entity evaluation , our C - GCN model also outperforms PA - LSTM by a substantial margin , suggesting its generalizability even when entities are not seen ."
          }
        }
      },
      "has" : {
        "Effect of Path - centric Pruning" : {
          "compare" : ["two GCN models", 
          {"Tree - LSTM" : 
          {"when" : {"pruning distance K" : {"is" : "varied"}}}}, 
          {"from sentence" : "Effect of Path - centric Pruning
To show the effectiveness of path - centric pruning , we compare the two GCN models and the Tree - LSTM when the pruning distance K is varied ."

		}
          ],
          "performance of" : {
            "all three models" : {
              "peaks when" : {
                "K = 1" : {
                  "outperforming" : "respective dependency path - based counterpart ( K = 0 )"
                }
              }
            },
            "from sentence" : "As shown in , the performance of all three models peaks when K = 1 , outperforming their respective dependency path - based counterpart ( K = 0 ) ."
          },
          "find" : {
            "all three models" : {
              "are" : {
                "less effective" : {
                  "when" : {
                    "entire dependency tree" : {
                      "is" :  "present"
                    }
                  }
                }
              }
            },
            "from sentence" : "We find that all three models are less effective when the entire dependency tree is present , indicating that including extra information hurts performance ."            
          },
          "contextualizing" : {
            "GCN" : {
              "makes it" : {
                "less sensitive" : {
                  "to changes in" : "tree structures provided"
                }
              }
            },
            "from sentence" : "Finally , we note that contextualizing the GCN makes it less sensitive to changes in the tree structures provided , presumably because the model can use word sequence information in the LSTM layer to recover any off - path information that it needs for correct relation extraction ."
          }
        }
      }
    }
  }
}