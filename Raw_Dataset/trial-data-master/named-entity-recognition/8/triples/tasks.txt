(Contribution||has||Tasks)
(Tasks||has||SQuAD v 1.1)
(SQuAD v 1.1||name||Stanford Question Answering Dataset ( SQuAD v1.1 ))
(SQuAD v 1.1||has||Hyperparameters)
(Hyperparameters||fine - tune||3 epochs)
(3 epochs||learning rate||5 e - 5)
(3 epochs||batch size||32)
(SQuAD v 1.1||has||Results)
(Results||has||best performing system)
(best performing system||outperforms||top leaderboard system)
(top leaderboard system||by||+ 1.5 F1)
(+ 1.5 F1||in||ensembling)
(top leaderboard system||by||+ 1.3 F1)
(+ 1.3 F1||as||single system)
(Tasks||has||SQuAD v 2.0)
(SQuAD v 2.0||has||Hyperparameters)
(Hyperparameters||fine - tuned||2 epochs)
(2 epochs||learning rate||5 e - 5)
(2 epochs||batch size||48)
(SQuAD v 2.0||has||Results)
(Results||observe||+ 5.1 F1 improvement)
(+ 5.1 F1 improvement||over||previous best system)
(Tasks||has||GLUE)
(GLUE||name||General Language Understanding Evaluation ( GLUE ))
(GLUE||has||Hyperparameters)
(Hyperparameters||use||batch size)
(batch size||of||32)
(Hyperparameters||fine - tune||for 3 epochs)
(for 3 epochs||over||data for all GLUE tasks)
(Hyperparameters||for||BERT LARGE)
(BERT LARGE||ran||several random restarts)
(several random restarts||selected||best model on the Dev set)
(Hyperparameters||selected||best fine - tuning learning rate)
(best fine - tuning learning rate||among||5 e - 5 , 4 e - 5 , 3 e - 5 , and 2 e - 5)
(best fine - tuning learning rate||on||Dev set)
(GLUE||has||Results)
(Results||has||BERT LARGE)
(BERT LARGE||significantly outperforms||BERT BASE)
(BERT BASE||across||all tasks)
(Results||has||BERT BASE and BERT LARGE)
(BERT BASE and BERT LARGE||outperform||all systems on all tasks)
(all systems on all tasks||by||substantial margin)
(substantial margin||obtaining||4.5 % and 7.0 % respective average accuracy improvement)
(4.5 % and 7.0 % respective average accuracy improvement||over||prior state of the art)
(Tasks||has||SWAG)
(SWAG||name||Situations With Adversarial Generations)
(SWAG||has||Hyperparameters)
(Hyperparameters||fine - tune||3 epochs)
(3 epochs||learning rate||2 e - 5)
(3 epochs||batch size||16)
(SWAG||has||Results)
(Results||has||BERT LARGE)
(BERT LARGE||outperforms||OpenAI GPT)
(OpenAI GPT||by||8.3 %)
(BERT LARGE||outperforms||authors ' baseline ESIM + ELMo system)
(authors ' baseline ESIM + ELMo system||by||+ 27.1 %)
