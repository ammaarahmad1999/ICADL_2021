{
  "has" : {
    "Tasks" : {
      "has" : {
        "Textual entailment" : {
          "has" : {
            "Stanford Natural Language Inference ( SNLI )" : {
              "improves" : {
                "accuracy" : {
                  "by" : {
                    "average of 0.7 %" : {
                      "across" : "five random seeds"
                    }
                  },
                  "adding" : {
                    "ELMo" : {
                      "to" : "ESIM model"
                    }
                  }
                }
              }
            }
          },
          "from sentence" : "Textual entailment is the task of determining whether a \" hypothesis \" is true , given a \" premise \" .
The Stanford Natural Language Inference ( SNLI ) corpus provides approximately 550K hypothesis / premise pairs .
Overall , adding ELMo to the ESIM model improves accuracy by an average of 0.7 % across five random seeds ."

        },
        "Coreference resolution" : {
          "with" : {
            "OntoNotes coreference annotations" : {
              "from" : "CoNLL 2012 shared task",
              "improved" : {
                "average F 1 by 3.2 %" : {
                  "from" : "67.2 to 70.4",
                  "adding" : "ELMo"
                }
              }
            }
          },
          "from sentence" : "As shown in Coreference resolution Coreference resolution is the task of clustering mentions in text that refer to the same underlying real world entities .
In our experiments with the OntoNotes coreference annotations from the CoNLL 2012 shared task , adding ELMo improved the average F 1 by 3.2 % from 67.2 to 70.4 , establishing a new state of the art , again improving over the previous best ensemble result by 1.6 % F 1 ."

        }
      }
    }
  }
}