(Contribution||has||Experimental setup)
(Experimental setup||At||test time)
(test time||are used||moving averages)
(moving averages||instead of||raw weights)
(Experimental setup||use||100 1D filters)
(100 1D filters||with||width of 5)
(100 1D filters||for||CNN char embedding)
(Experimental setup||use||AdaDelta ( Zeiler , 2012 ) optimizer)
(AdaDelta ( Zeiler , 2012 ) optimizer||with||minibatch size)
(minibatch size||of||60)
(AdaDelta ( Zeiler , 2012 ) optimizer||with||initial learning rate)
(initial learning rate||of||0.5)
(initial learning rate||for||12 epochs)
(Experimental setup||has||Each paragraph and question)
(Each paragraph and question||tokenized by||regular - expression - based word tokenizer ( PTB Tokenizer ))
(Each paragraph and question||fed into||model)
(Experimental setup||has||dropout ) rate)
(dropout ) rate||of||0.2)
(0.2||used for||CNN)
(0.2||used for||all LSTM layers)
(0.2||used for||linear transformation)
(linear transformation||before||softmax)
(softmax||for||answers)
(Experimental setup||has||training process)
(training process||takes||roughly 20 hours)
(roughly 20 hours||on||single Titan X GPU)
(Experimental setup||has||The model)
(The model||has about||2.6 million parameters)
(Experimental setup||has||hidden state size ( d ))
(hidden state size ( d )||of||model)
(model||is||100)
(Experimental setup||During||training)
(training||has||moving averages)
(moving averages||of||all weights)
(all weights||of||model)
(all weights||maintained with||exponential decay rate)
(exponential decay rate||of||0.999)
