(Contribution||has||Experimental setup)
(Experimental setup||apply||dropout)
(dropout||with||dropout rate)
(dropout rate||of||0.2)
(dropout||between||layers)
(Experimental setup||use||hidden size)
(hidden size||to compute||attention scores)
(attention scores||is||75)
(Experimental setup||use||hidden vector length)
(hidden vector length||set to||75)
(75||for||all layers)
(Experimental setup||use||tokenizer)
(tokenizer||from||Stanford CoreNLP)
(tokenizer||to preprocess||each passage and question)
(Experimental setup||utilize||3 layers of bi-directional GRU)
(3 layers of bi-directional GRU||to encode||questions and passages)
(Experimental setup||utilize||gated attention - based recurrent network)
(gated attention - based recurrent network||for||question and passage matching)
(gated attention - based recurrent network||encoded||bidirectionally)
(Experimental setup||utilize||1 layer of bi-directional GRU)
(1 layer of bi-directional GRU||to compute||character - level embeddings)
(Experimental setup||For||word embedding)
(word embedding||use||zero vectors)
(zero vectors||to represent||all out - of - vocab words)
(word embedding||use||pretrained case - sensitive GloVe embeddings)
(pretrained case - sensitive GloVe embeddings||for||questions and passages)
(pretrained case - sensitive GloVe embeddings||has||fixed)
(fixed||during||training)
(Experimental setup||has||Gated Recurrent Unit variant)
(Gated Recurrent Unit variant||of||LSTM)
(Gated Recurrent Unit variant||used throughout||our model)
(Experimental setup||has||model)
(model||optimized with||AdaDelta ( Zeiler , 2012 ))
(AdaDelta ( Zeiler , 2012 )||with||initial learning rate)
(initial learning rate||of||1)
(Experimental setup||used in||AdaDelta)
(AdaDelta||are||0.95 and 1e ? 6)
