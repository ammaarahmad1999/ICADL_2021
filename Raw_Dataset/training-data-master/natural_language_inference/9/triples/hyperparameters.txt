(Contribution||has||Hyperparameters)
(Hyperparameters||withhold||10 %)
(10 %||of||training)
(10 %||for||development)
(Hyperparameters||use||hidden state size)
(hidden state size||of||50)
(50||by||deafult)
(Hyperparameters||repeat||each training procedure)
(each training procedure||has||10 times ( 50 times for 10 k ))
(10 times ( 50 times for 10 k )||with||new random initialization)
(new random initialization||of||weights)
(Hyperparameters||has||Forget bias)
(Forget bias||of||2.5)
(2.5||used for||update gates)
(Hyperparameters||has||loss function)
(loss function||is||cross entropy)
(cross entropy||between||v and the one - hot vector)
(v and the one - hot vector||of||true answer)
(Hyperparameters||has||loss)
(loss||minimized by||stochastic gradient descent)
(stochastic gradient descent||for||maximally 500 epochs)
(Hyperparameters||has||Batch sizes)
(Batch sizes||of||128)
(128||for||bAbI QA 10 k)
(Batch sizes||of||32)
(32||for||bAbI story - based QA 1k)
(32||for||bAb I dialog)
(32||for||DSTC2 dialog)
(Hyperparameters||has||learning rate)
(learning rate||controlled by||AdaGrad)
(AdaGrad||with||initial learning rate)
(initial learning rate||of||0.5 ( 0.1 for QA 10 k ))
(Hyperparameters||has||L2 weight decay)
(L2 weight decay||of||0.001 ( 0.0005 for QA 10 k ))
(0.001 ( 0.0005 for QA 10 k )||used for||all weights)
(Hyperparameters||has||training)
(training||is||early stopped)
(early stopped||if||loss)
(loss||has||not decrease)
(not decrease||for||50 epochs)
(loss||on||development data)
(Hyperparameters||has||weights)
(weights||in||input and output modules)
(input and output modules||initialized with||zero mean)
(input and output modules||initialized with||standard deviation of 1 / ? d)
