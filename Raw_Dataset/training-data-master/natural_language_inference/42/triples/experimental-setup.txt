(Contribution||has||Experimental setup)
(Experimental setup||set||feed - forward hidden size)
(feed - forward hidden size||to||200)
(200||in||processing layers)
(feed - forward hidden size||to||400)
(400||in||reduction layer)
(Experimental setup||set||processing layers dimension)
(processing layers dimension||has||d model)
(d model||to||100)
(Experimental setup||set||number of heads)
(number of heads||has||n heads)
(n heads||in||each attention sublayer)
(each attention sublayer||to||4)
(Experimental setup||trained||FABIR model)
(FABIR model||with||batch size)
(batch size||of||75)
(FABIR model||in||GPU NVidia Titan X)
(GPU NVidia Titan X||with||12 GB)
(12 GB||of||RAM)
(FABIR model||during||54 epochs)
(Experimental setup||pre-processed||texts)
(texts||with||NLTK Tokenizer)
(Experimental setup||In||character - level embedding process)
(character - level embedding process||has||dropout)
(dropout||of||0.75)
(0.75||added before||convolution)
(Experimental setup||For||regularization)
(regularization||applied||residual and attention dropout)
(residual and attention dropout||of||0.8)
(0.8||in||reduction layer)
(residual and attention dropout||of||0.9)
(0.9||in||processing layers)
(Experimental setup||has||dropout)
(dropout||of||0.8)
(0.8||added before||each convolutional layer)
(each convolutional layer||in||answer selector)
(Experimental setup||developed||our model)
(our model||in||Tensorflow)
