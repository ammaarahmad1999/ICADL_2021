(Contribution||has||Experiments)
(Experiments||has||Tasks)
(Tasks||has||Natural Language Inference)
(Natural Language Inference||has||Experimental setup)
(Experimental setup||initialize||word embedding matrix)
(word embedding matrix||with||GloVe 300D pretrained vectors)
(Experimental setup||has||dropout probability)
(dropout probability||set to||0.2)
(Experimental setup||has||size)
(size||of||mini-batches)
(mini-batches||set to||128)
(Experimental setup||has||temperature parameter)
(temperature parameter||of||Gumbel - Softmax)
(Gumbel - Softmax||set to||1.0)
(Experimental setup||For training||models)
(models||used||Adam optimizer)
(Experimental setup||on||machine)
(machine||with||NVIDIA Titan Xp GPU)
(Natural Language Inference||has||Results)
(Results||find that||our 100D and 300D model)
(our 100D and 300D model||outperform||all other models)
(all other models||of||similar numbers of parameters)
(Results||see that||LSTM - based leaf transformation)
(LSTM - based leaf transformation||has||clear advantage)
(clear advantage||over||affine - transformation - based one)
(Results||has||Our 600D model)
(Our 600D model||achieves||accuracy)
(accuracy||of||86.0 %)
(86.0 %||comparable to||state - of - the - art model)
(Tasks||has||Sentiment Analysis)
(Sentiment Analysis||has||Hyperparameters)
(Hyperparameters||trained||SST - 2 model)
(SST - 2 model||apply||dropout ( p = 0.5 ))
(dropout ( p = 0.5 )||on||output)
(output||of||word embedding layer)
(dropout ( p = 0.5 )||on||input and the output)
(input and the output||of||MLP layer)
(SST - 2 model||with hyperparameters||D x = 300 , D h = 300 , D c = 300)
(SST - 2 model||has||Adadelta optimizer)
(Adadelta optimizer||used for||optimization)
(SST - 2 model||has||size)
(size||of||mini-batches)
(mini-batches||set to||32)
(SST - 2 model||has||word vectors)
(word vectors||has||fine - tuned)
(fine - tuned||during||training)
(word vectors||has||initialized)
(initialized||with||GloVe 300D pretrained vectors)
(Hyperparameters||For||SST - 5 model)
(SST - 5 model||optimize||model)
(model||using||Adadelta optimizer)
(Adadelta optimizer||with||batch size 64)
(Adadelta optimizer||apply||dropout)
(dropout||with||p = 0.5)
(SST - 5 model||has||hyperparameters)
(hyperparameters||set to||D x = 300 , D h = 300 , D c = 1024)
(Hyperparameters||is||single - hidden layer MLP)
(single - hidden layer MLP||with||ReLU activation function)
(Sentiment Analysis||has||Results)
(Results||utilizing||pretraining and character n-gram embeddings)
(pretraining and character n-gram embeddings||improves||validation accuracy)
(validation accuracy||by||2.8 % ( SST - 2 ))
(validation accuracy||by||1.7 % ( SST - 5 ))
(Results||has||SST - 2 model)
(SST - 2 model||outperforms||all other models)
(all other models||except||byte - m LSTM)
(all other models||has||substantially)
(Results||see that||performance)
(performance||of||our SST - 5 model)
(our SST - 5 model||on par with||current state - of - the - art model)
