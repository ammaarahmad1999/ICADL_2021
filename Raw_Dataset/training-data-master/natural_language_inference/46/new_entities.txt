39	45	49	p	call
39	50	61	n	NarrativeQA
40	12	23	p	consists of
40	24	31	n	stories
40	34	43	p	which are
40	44	67	n	books and movie scripts
40	70	74	p	with
40	75	110	n	human written questions and answers
40	111	126	p	based solely on
40	127	166	n	human - generated abstractive summaries
41	19	28	n	questions
41	29	34	p	maybe
41	35	43	n	answered
41	44	49	p	using
41	59	68	n	summaries
41	76	91	n	full story text
196	0	22	n	Reading Summaries Only
201	35	63	n	neural span prediction model
201	64	91	n	significantly outperforming
201	92	118	n	all other proposed methods
203	0	59	n	Both the plain sequence to sequence model and the AS Reader
203	140	147	p	perform
203	148	152	n	well
205	3	28	n	additional inductive bias
205	29	39	p	results in
205	40	58	n	higher performance
205	59	62	p	for
205	67	88	n	span prediction model
208	23	25	p	on
208	30	55	n	full Narra - tive QA task
208	58	63	p	where
208	68	85	n	context documents
208	86	89	p	are
208	90	102	n	full stories
209	33	40	p	observe
209	43	50	n	decline
209	51	53	p	in
209	54	65	n	performance
209	66	68	p	of
209	73	104	n	span- selection oracle IR model
215	0	25	n	Reading Full Stories Only
224	4	13	n	AS Reader
224	80	93	n	underperforms
224	98	133	n	simple no -context Seq2Seq baseline
224	147	158	p	in terms of
224	159	162	n	MRR
229	27	35	p	observed
229	36	62	n	no significant differences
229	63	66	p	for
229	67	74	n	varying
229	75	91	n	number of chunks
2	16	37	n	Reading Comprehension
4	0	28	n	Reading comprehension ( RC )
5	52	54	n	RC
