(Contribution||has||Model)
(Model||In||ReSA)
(ReSA||has||two parameter - untied RSS)
(two parameter - untied RSS||applied to||two copies)
(two copies||of||input sequence)
(Model||build||sentence - encoding model)
(sentence - encoding model||based on||ReSA)
(ReSA||without||any CNN / RNN structure)
(sentence - encoding model||name||reinforced self - attention network ( ReSAN ))
(Model||develop||reinforced self - attention ( ReSA ))
(reinforced self - attention ( ReSA )||combines||RSS)
(RSS||with||soft self - attention)
(Model||has||Re SA)
(Re SA||models||sparse dependencies)
(sparse dependencies||between||head and dependent tokens)
(head and dependent tokens||selected by||two RSS modules)
(Model||propose||novel hard attention mechanism)
(novel hard attention mechanism||selects||tokens)
(tokens||from||input sequence)
(input sequence||in||parallel)
(novel hard attention mechanism||called||reinforced sequence sampling ( RSS ))
(novel hard attention mechanism||is||highly parallelizable)
(highly parallelizable||without||any recurrent structure)
