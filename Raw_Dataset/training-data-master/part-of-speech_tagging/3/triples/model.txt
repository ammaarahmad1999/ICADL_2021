(Contribution||has||Model)
(Model||first use||convolutional neural networks ( CNNs ))
(convolutional neural networks ( CNNs )||to encode||character - level information)
(character - level information||of||a word)
(a word||into||its character - level representation)
(Model||easily applied to||wide range)
(wide range||of||sequence labeling tasks)
(sequence labeling tasks||on||different languages and domains)
(Model||is||endto - end model)
(endto - end model||requiring no||task - specific resources)
(endto - end model||requiring no||feature engineering)
(endto - end model||requiring no||data pre-processing)
(endto - end model||beyond||pre-trained word embeddings)
(pre-trained word embeddings||on||unlabeled corpora)
(Model||On top of||BLSTM)
(BLSTM||use||sequential CRF)
(sequential CRF||to jointly decode||labels)
(labels||for||whole sentence)
(Model||propose||neural network architecture)
(neural network architecture||for||sequence labeling)
(Model||combine||character - and word - level representations)
(character - and word - level representations||feed them into||bi-directional LSTM ( BLSTM ))
(bi-directional LSTM ( BLSTM )||to model||context information)
(context information||of||each word)
