167	0	10	p	shows that
167	11	38	n	separately optimized models
167	39	42	p	are
167	43	70	n	significantly more accurate
167	71	73	p	on
167	74	81	n	average
167	82	86	p	than
167	87	111	n	jointly optimized models
168	47	50	p	for
168	0	21	n	Separate optimization
168	22	30	p	leads to
168	31	46	n	better accuracy
168	74	77	p	for
168	51	73	n	34 out of 40 treebanks
168	114	117	p	for
168	82	109	n	morphological features task
168	118	140	n	30 out of 39 treebanks
168	141	144	p	for
168	145	157	n	xpos tagging
169	22	34	n	outperformed
169	35	53	n	joint optimization
169	54	56	p	by
169	57	83	n	up to 2.1 percent absolute
169	92	97	n	joint
169	98	103	p	never
169	104	119	n	out - performed
169	120	128	n	separate
169	129	131	p	by
169	132	156	n	more than 0.5 % absolute
179	27	41	n	combined model
179	46	75	n	significantly higher accuracy
179	76	89	p	compared with
179	101	126	n	character and word models
194	0	3	p	For
194	4	28	n	all of the network sizes
194	29	31	p	in
194	36	47	n	grid search
194	59	74	p	observed during
194	75	83	n	training
194	84	88	p	that
194	93	101	n	accuracy
194	102	107	p	reach
194	110	120	n	high value
194	125	138	p	degrades with
194	139	154	n	more iterations
194	155	158	p	for
194	163	187	n	character and word model
119	4	19	n	word embeddings
119	20	23	p	are
119	24	35	n	initialized
119	36	40	p	with
119	41	52	n	zero values
119	61	83	n	pre-trained embeddings
119	88	91	p	not
119	92	99	n	updated
119	100	106	p	during
119	107	115	n	training
120	4	11	n	dropout
120	12	19	p	used on
120	24	34	n	embeddings
120	38	49	p	achieved by
120	52	56	n	RRIE
120	35	37	p	is
120	64	91	n	relative reduction in error
24	34	39	p	learn
24	40	100	n	context sensitive initial character and word representations
24	101	108	p	through
24	109	155	n	two separate sentence - level recurrent models
25	15	27	p	combined via
25	30	47	n	meta-BiLSTM model
25	53	59	p	builds
25	62	84	n	unified representation
25	85	87	p	of
25	88	97	n	each word
25	111	119	p	used for
25	120	137	n	syntactic tagging
2	0	23	n	Morphosyntactic Tagging
135	0	34	n	Part - of - Speech Tagging Results
141	0	9	n	Our model
141	10	21	n	outperforms
141	22	24	p	in
141	25	27	n	32
141	28	30	p	of
141	35	47	n	54 treebanks
141	48	52	p	with
141	53	60	n	13 ties
143	19	26	p	produce
143	27	41	n	better results
143	44	58	p	especially for
143	59	89	n	morphologically rich languages
150	0	29	n	Morphological Tagging Results
155	0	10	n	Our models
155	19	26	p	produce
155	27	55	n	significantly better results
155	56	60	p	than
155	65	102	n	winners of the CoNLL 2017 Shared Task
