(Contribution||has||Baselines)
(Baselines||has||TNet - AS)
(TNet - AS||Without using||attention module)
(Baselines||has||IAN)
(IAN||adopts||two LSTMs)
(two LSTMs||to derive||representations)
(representations||of||context and the target phrase)
(IAN||has||concatenation)
(concatenation||fed to||softmax layer)
(Baselines||has||BILSTM - ATT -G)
(BILSTM - ATT -G||models||left and right contexts)
(left and right contexts||using||two attention - based LSTMs)
(BILSTM - ATT -G||makes use of||special gate layer)
(special gate layer||to combine||two representations)
(Baselines||has||TC - LSTM)
(TC - LSTM||has||concatenation)
(concatenation||of||two representations)
(two representations||used to||predict)
(predict||has||label)
(TC - LSTM||has||Two LSTMs)
(Two LSTMs||used to||model)
(model||has||left and right context)
(left and right context||of||target)
(Baselines||has||MemNet)
(MemNet||uses||attention mechanism)
(attention mechanism||over||word embedding)
(word embedding||over||multiple rounds)
(attention mechanism||to aggregate||information)
(information||in||sentence)
