161	51	68	p	implemented using
161	73	96	n	Tensor Flow python pack
162	3	11	p	minimize
162	16	34	n	crossentropy error
162	35	40	p	using
162	45	59	n	Adam optimizer
162	64	80	n	L2regularization
162	81	83	p	on
162	88	102	n	set of weights
163	0	3	p	For
163	8	44	n	individual models ( before joining )
163	50	53	p	use
163	54	73	n	200 training epochs
163	80	90	n	batch size
163	91	93	p	of
163	94	97	n	100
107	4	13	n	framework
107	14	25	p	consists of
107	26	46	n	three main sub parts
108	0	5	p	Given
108	8	26	n	segmented sentence
108	33	43	n	first step
108	47	56	p	to create
108	57	90	n	meaningful vector representations
108	91	94	p	for
108	95	107	n	all the EDUs
109	10	16	p	devise
109	17	60	n	three different Recursive Neural Net models
109	68	80	p	designed for
109	81	84	n	one
109	85	87	p	of
109	88	118	n	discourse structure prediction
109	121	150	n	discourse relation prediction
109	155	173	n	sentiment analysis
110	13	17	p	join
110	24	35	n	Neural Nets
110	36	38	p	in
110	39	57	n	two different ways
110	60	72	n	Multitasking
110	77	89	n	Pre-training
2	33	88	n	Sentence Level Discourse Parsing and Sentiment Analysis
169	22	25	p	see
169	26	42	n	some improvement
169	43	45	p	on
169	46	76	n	Discourse Structure prediction
169	77	94	p	when we are using
169	97	108	n	joint model
169	117	128	n	improvement
169	129	131	p	is
169	132	157	n	statistically significant
169	158	166	p	only for
169	171	206	n	Nuclearity and Relation predictions
170	4	16	n	improvements
170	17	19	p	on
170	24	44	n	Relation predictions
170	50	59	p	mainly on
170	64	79	n	Contrastive set
170	82	94	p	specifically
170	108	116	n	Contrast
170	119	129	n	Comparison
170	134	139	n	Cause
178	0	2	p	In
178	7	27	n	fine grained setting
178	31	38	p	compute
178	43	51	n	accuracy
178	52	54	p	of
178	55	66	n	exact match
178	67	73	p	across
178	74	86	n	five classes
