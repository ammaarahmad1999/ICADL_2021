(Contribution||has||Baselines)
(Baselines||design||basic BERT - based model)
(basic BERT - based model||to evaluate||performance)
(performance||of||AEN - BERT)
(Baselines||has||Non - RNN based baselines)
(Non - RNN based baselines||has||Feature - based SVM)
(Feature - based SVM||is||traditional support vector machine based model)
(traditional support vector machine based model||with||extensive feature engineering)
(Non - RNN based baselines||has||Rec - NN)
(Rec - NN||learns||sentence representation)
(sentence representation||toward||target)
(sentence representation||via||semantic composition)
(semantic composition||using||Recursive NNs)
(Rec - NN||uses||rules)
(rules||to transform||dependency tree)
(Rec - NN||put||opinion target)
(opinion target||at||root)
(Non - RNN based baselines||has||MemNet)
(MemNet||uses||multi-hops of attention layers)
(multi-hops of attention layers||to explicitly captures||importance)
(importance||of||each context word)
(multi-hops of attention layers||on||context word embeddings)
(context word embeddings||for||sentence representation)
(Baselines||has||Basic BERT - based model)
(Basic BERT - based model||has||BERT - SPC)
(BERT - SPC||feeds||sequence " [ CLS ] + context + [ SEP ] + target + [ SEP ] ")
(sequence " [ CLS ] + context + [ SEP ] + target + [ SEP ] "||into||basic BERT model)
(sequence " [ CLS ] + context + [ SEP ] + target + [ SEP ] "||for||sentence pair classification task)
(Baselines||has||AEN - Glo Ve ablations)
(AEN - Glo Ve ablations||has||AEN - GloVe w/ o LSR)
(AEN - GloVe w/ o LSR||ablates||label smoothing regularization)
(AEN - Glo Ve ablations||has||AEN-GloVe-BiLSTM)
(AEN-GloVe-BiLSTM||replaces||attentional encoder layer)
(attentional encoder layer||with||two bidirectional LSTM)
(AEN - Glo Ve ablations||has||AEN - GloVe w/ o MHA)
(AEN - GloVe w/ o MHA||ablates||MHA module)
(AEN - Glo Ve ablations||has||AEN - GloVe w/ o PCT)
(AEN - GloVe w/ o PCT||ablates||PCT module)
(Baselines||has||RNN based baselines)
(RNN based baselines||has||IAN)
(IAN||learns||representations)
(representations||of||target and context)
(target and context||with||two LSTMs and attentions)
(target and context||which generates||representations)
(representations||for||targets and contexts)
(targets and contexts||with respect to||each other)
(RNN based baselines||has||ATAE - LSTM)
(ATAE - LSTM||use||LSTM)
(LSTM||with||attention)
(attention||to get||final representation)
(final representation||for||classification)
(ATAE - LSTM||strengthens||effect of target embeddings)
(effect of target embeddings||which appends||target embeddings)
(target embeddings||with||each word embeddings)
(RNN based baselines||has||TD - LSTM)
(TD - LSTM||extends||LSTM)
(LSTM||by using||two LSTM networks)
(LSTM||to model||right context)
(right context||with||target)
(LSTM||to model||left context)
(left context||with||target)
(RNN based baselines||has||RAM)
(RAM||using||gated recurrent unit network)
(gated recurrent unit network||to combine||multiple attention outputs)
(multiple attention outputs||for||sentence representation)
(RAM||strengthens||Mem - Net)
(Mem - Net||by representing||memory)
(memory||with||bidirectional LSTM)
