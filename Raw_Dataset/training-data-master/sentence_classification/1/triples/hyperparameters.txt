(Contribution||has||Hyperparameters)
(Hyperparameters||fixed during||training phase)
(training phase||to avoid||over-fitting)
(Hyperparameters||For||regularization)
(regularization||has||dropout)
(dropout||applied to||each layer)
(Hyperparameters||has||window sizes)
(window sizes||of||CNN encoder)
(CNN encoder||in||sentence encoding layer)
(sentence encoding layer||are||2 , 3 , 4 and 5)
(Hyperparameters||has||learning rate)
(learning rate||initially set||0.003)
(learning rate||decayed by||0.9)
(0.9||after||each epoch)
(Hyperparameters||has||token embeddings)
(token embeddings||using||word2vec tool)
(token embeddings||pre-trained on||large corpus)
(large corpus||combining||Wikipedia , PubMed , and PMC texts)
(Hyperparameters||trained using||Adam optimization method)
(Hyperparameters||adopted||dropout)
(dropout||with||expectation - linear regularization)
(expectation - linear regularization||improve||generaliza - tion performance)
(expectation - linear regularization||to explicitly control||inference gap)
(Hyperparameters||optimized via||grid search)
(grid search||based on||validation set)
