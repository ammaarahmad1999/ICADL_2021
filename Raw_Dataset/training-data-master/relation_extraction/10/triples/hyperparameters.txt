(Contribution||has||Hyperparameters)
(Hyperparameters||limit||spans)
(spans||to||max length)
(max length||of||L = 10)
(Hyperparameters||has||Learning)
(Learning||done with||Adam ( Kingma and Ba , 2015 ))
(Adam ( Kingma and Ba , 2015 )||with||default parameters)
(Hyperparameters||has||Early Stopping)
(Early Stopping||of||20 evaluations)
(20 evaluations||on||dev set)
(Hyperparameters||has||learned character embeddings)
(learned character embeddings||of size||8)
(Hyperparameters||has||Regularization Dropout)
(Regularization Dropout||applied with||dropout rate 0.2)
(dropout rate 0.2||to||all hidden layers)
(all hidden layers||of||all MLPs and feature encodings)
(Regularization Dropout||applied with||dropout rate 0.4)
(dropout rate 0.4||to||all LSTM layer outputs)
(Regularization Dropout||applied with||dropout rate 0.5)
(dropout rate 0.5||to||all word and character embeddings)
(Hyperparameters||has||learning rate)
(learning rate||annealed by||1 %)
(1 %||every||100 iterations)
(Hyperparameters||has||1 - dimensional convolutions)
(1 - dimensional convolutions||of window size||3)
(Hyperparameters||has||All Multi Layer Perceptrons ( MLP ))
(All Multi Layer Perceptrons ( MLP )||has||two hidden layers)
(two hidden layers||with||500 dimensions)
(two hidden layers||followed by||ReLU activation)
(Hyperparameters||has||Minibatch Size)
(Minibatch Size||is||1)
(Hyperparameters||has||stacked bi - LSTMs)
(stacked bi - LSTMs||has||3 layers)
(3 layers||with||200 - dimensional hidden states)
(3 layers||with||highway connections)
(Hyperparameters||consider||spans)
(spans||entirely within||sentence)
