(Contribution||has||Hyperparameters)
(Hyperparameters||minimize||cross - entropy loss)
(cross - entropy loss||over||all 42 relations)
(cross - entropy loss||using||AdaGrad)
(Hyperparameters||set||p)
(p||to be||0.06)
(0.06||for||SDP - LSTM model)
(p||to be||0.04)
(0.04||for||all other models)
(Hyperparameters||apply||Dropout)
(Dropout||with||p = 0.5)
(p = 0.5||to||CNNs and LSTMs)
(Hyperparameters||use||pre-trained GloVe vectors)
(pre-trained GloVe vectors||to initialize||word embeddings)
(Hyperparameters||For||all the LSTM layers)
(all the LSTM layers||find that||2 - layer stacked LSTMs)
(2 - layer stacked LSTMs||work better than||one - layer LSTMs)
(Hyperparameters||map||words)
(words||occur less than||2 times)
(2 times||in||training set)
(words||to||special < UNK > token)
(Hyperparameters||During||training)
(training||find||word dropout strategy)
(word dropout strategy||randomly set||token)
(token||to be||< UNK >)
(< UNK >||with||probability p)
(word dropout strategy||to be||very effective)
