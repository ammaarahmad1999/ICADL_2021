(Contribution||has||Results)
(Results||observe that||novel attentionbased architecture)
(novel attentionbased architecture||achieves||new state - of - the - art results)
(Results||has||Att - Input - CNN)
(Att - Input - CNN||relies only on||primal attention)
(primal attention||at||input level)
(Att - Input - CNN||performing||standard max - pooling)
(standard max - pooling||after||convolution layer)
(convolution layer||to generate||network output w O)
(Results||has||Our full dual attention model Att - Pooling - CNN)
(Our full dual attention model Att - Pooling - CNN||achieves||even more favorable F1- score)
(even more favorable F1- score||of||88 %)
(Results||With||Att - Input - CNN)
(Att - Input - CNN||achieve||F1-score)
(F1-score||of||87.5 %)
(87.5 %||outperforming||an SVM - based approach ( 82.2 % ))
(87.5 %||outperforming||wellknown CR - CNN model ( 84.1 % ))
(87.5 %||outperforming||newly released DRNNs ( 85.8 % ))
