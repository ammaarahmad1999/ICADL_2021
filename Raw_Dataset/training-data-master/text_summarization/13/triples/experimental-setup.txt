(Contribution||has||Experimental setup)
(Experimental setup||At||test time)
(test time||run||beam search)
(beam search||to produce||summary)
(summary||with||beam size of 5)
(Experimental setup||use||2 layer LSTMs)
(2 layer LSTMs||with||500 hidden units)
(Experimental setup||use||dropout)
(dropout||between||stacked LSTM hidden states and before the final word generator layer)
(stacked LSTM hidden states and before the final word generator layer||to regularize||dropout probability 0.3)
(Experimental setup||For||convolutional layers)
(convolutional layers||use||kernel width)
(kernel width||of||6 and 600 filters)
(Experimental setup||implemented using||Torch)
(Torch||based on||past version of the Open NMT system)
(Experimental setup||initialize||all other parameters)
(all other parameters||as uniform in||interval [ ? 0.1 , 0.1 ])
(Experimental setup||initialize||learning rate)
(learning rate||to||1)
(1||for||rest of the model)
(learning rate||to||0.1)
(0.1||for||top - level encoder)
(learning rate||begin decaying it by||a factor of 0.5)
(a factor of 0.5||after||validation perplexity)
(validation perplexity||stops||decreasing)
(Experimental setup||initialize||word embeddings)
(word embeddings||with||300 dimensional word2vec embeddings)
(Experimental setup||has||Positional embeddings)
(Positional embeddings||have||dimension 25)
(Experimental setup||train with||minibatch stochastic gradient descent ( SGD ))
(minibatch stochastic gradient descent ( SGD )||with||batch size 20)
(batch size 20||for||20 epochs)
(minibatch stochastic gradient descent ( SGD )||renormalizing gradients||below norm 5)
(Experimental setup||ran||our experiments)
(our experiments||on||12GB Geforce GTX Titan X GPU)
