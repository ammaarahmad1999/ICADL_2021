(Contribution||has||Model)
(Model||treat||decoder attention weights)
(decoder attention weights||as||focused aspect of the generated summary)
(focused aspect of the generated summary||a.k.a.||decoder focused aspect)
(Model||After||each decoding step)
(each decoding step||designed||supervisor)
(supervisor||to measure||distance)
(distance||between||reader focused aspect and the decoder focused aspect)
(Model||calculate alignment between||reader comments words and document words)
(reader comments words and document words||regarded as||reader attention)
(reader attention||representing||reader focused aspect)
(Model||training of||framework RASG)
(framework RASG||conducted in||adversarial way)
(Model||propose||summarization framework)
(summarization framework||incorporates||reader comments)
(reader comments||to improve||summarization performance)
(summarization framework||named||reader - aware summary generator ( RASG ))
(Model||employed||seq2seq architecture with attention mechanism)
(seq2seq architecture with attention mechanism||as||basic summary generator)
