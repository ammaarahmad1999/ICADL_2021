(Contribution||has||Baselines)
(Baselines||For||Gigaword dataset)
(Gigaword dataset||compare our models with||Feat2s)
(Feat2s||is an||RNN sequence - to - sequence model)
(RNN sequence - to - sequence model||with||lexical and statistical features)
(lexical and statistical features||in||encoder)
(Gigaword dataset||compare our models with||Luong - NMT)
(Luong - NMT||is a||two - layer LSTM encoder - decoder model)
(Gigaword dataset||compare our models with||RAS - Elman)
(RAS - Elman||uses||attentive CNN encoder)
(RAS - Elman||uses||Elman RNN decoder)
(Gigaword dataset||compare our models with||ABS +)
(ABS +||is a||fine tuned version of ABS)
(fine tuned version of ABS||uses||attentive CNN encoder)
(fine tuned version of ABS||uses||NNLM decoder)
(Gigaword dataset||compare our models with||SEASS)
(SEASS||uses||BiGRU encoders)
(SEASS||uses||GRU decoders)
(GRU decoders||with||selective encoding)
(Baselines||For||CNN dataset)
(CNN dataset||compare our models with||Distraction - M3)
(Distraction - M3||uses||sequence - to - sequence abstractive model)
(sequence - to - sequence abstractive model||with||distraction - based networks)
(CNN dataset||compare our models with||GBA)
(GBA||is a||graph - based attentional neural abstractive model)
(CNN dataset||compare our models with||Lead - 3)
(Lead - 3||extracts||first three sentences of the document)
(first three sentences of the document||as||summary)
(CNN dataset||compare our models with||Bi - GRU)
(Bi - GRU||is a||non-hierarchical one - layer sequence - to - sequence abstractive baseline)
(CNN dataset||compare our models with||LexRank)
(LexRank||extracts||texts)
(texts||using||LexRank)
