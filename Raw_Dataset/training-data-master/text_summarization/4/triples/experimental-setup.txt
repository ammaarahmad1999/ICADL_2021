(Contribution||has||Experimental setup)
(Experimental setup||reduce||size of the input , output , and entity vocabularies)
(size of the input , output , and entity vocabularies||to||at most 50 K)
(Experimental setup||set||batch sizes)
(batch sizes||of||Gigaword and CNN datasets)
(Gigaword and CNN datasets||to||80 and 10)
(Experimental setup||use||dropout)
(dropout||on||all non-linear connections)
(all non-linear connections||with||dropout rate of 0.5)
(Experimental setup||use||beam search)
(beam search||of size||10)
(10||to generate||summary)
(Experimental setup||replace||less frequent words)
(less frequent words||to||< unk >)
(Experimental setup||For||firm attention)
(firm attention||tuned||k)
(k||by calculating||perplexity)
(perplexity||of||model)
(model||starting with||smaller values ( i.e. k = 1 , 2 , 5 , 10 , 20 , ... ))
(model||stopping when||perplexity of the model becomes worse)
(perplexity of the model becomes worse||than||previous model)
(Experimental setup||For||CNN)
(CNN||set||h = 3 , 4 , 5)
(h = 3 , 4 , 5||with||400 , 300 , 300 feature maps)
(Experimental setup||For||GRUs)
(GRUs||set||state size)
(state size||to||500)
(Experimental setup||Training is done via||stochastic gradient descent)
(stochastic gradient descent||over||shuffled mini-batches)
(shuffled mini-batches||with||Adadelta update rule)
(shuffled mini-batches||with||l 2 constraint ( Hinton et al. , 2012 ) of 3)
(Experimental setup||perform||early stopping)
(early stopping||using||subset of the given development dataset)
(Experimental setup||initialize||word and entity vectors)
(word and entity vectors||use||pre-trained vectors)
(pre-trained vectors||name||300D Glove)
(pre-trained vectors||name||1000D wiki2vec)
